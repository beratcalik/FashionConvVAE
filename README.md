# Convolutional Variational Autoencoder (ConvVAE) on Fashion-MNIST

## Introduction  
Variational Autoencoder (VAE) modelleri, hem sÄ±kÄ±ÅŸtÄ±rma (compression) hem de yeni veri Ã¼retme (generation) yeteneÄŸine sahip generatif modellerdir.  
Bu projede, 28Ã—28 gri-ton Fashion-MNIST veri seti Ã¼zerinde bir **Convolutional VAE (ConvVAE)** eÄŸitildi. AmaÃ§lar:  
1. GÃ¶rÃ¼ntÃ¼lerin yÃ¼ksek boyutlu piksellerini, dÃ¼ÅŸÃ¼k boyutlu latent uzayda temsil edebilmek  
2. Bu temsillerden rekonstrÃ¼ksiyon ve yeni Ã¶rnekler Ã¼retebilmek  
3. Encoderâ€™Ä±n Ã§Ä±kardÄ±ÄŸÄ± latent kodlarÄ± kullanarak downstream bir sÄ±nÄ±flandÄ±rma gÃ¶revi yapmak

## Methods

### Veri HazÄ±rlama  
- **Veri KÃ¼mesi**: Fashion-MNIST (60 000 eÄŸitim, 10 000 test Ã¶rneÄŸi).  
- **Ã–znitelik Boyutu**: Her Ã¶rnek 28Ã—28 piksel, gri-ton.  
- **Normalize Etme**: Piksel deÄŸerleri [0, 1] aralÄ±ÄŸÄ±na Ã§ekildi (PyTorch `ToTensor()` ile).  
- **Batchleme**: EÄŸitim iÃ§in `batch_size = 128`, test iÃ§in `batch_size = 128`.  
- **DataLoader KullanÄ±mÄ±**:  
  ```python
  from torch.utils.data import DataLoader
  from torchvision import datasets, transforms

  transform = transforms.Compose([
      transforms.ToTensor()
  ])
  train_ds = datasets.FashionMNIST("data/fashion-mnist",
                                   train=True,
                                   download=True,
                                   transform=transform)
  test_ds = datasets.FashionMNIST("data/fashion-mnist",
                                  train=False,
                                  download=True,
                                  transform=transform)
  train_loader = DataLoader(train_ds,
                            batch_size=128,
                            shuffle=True,
                            num_workers=4,
                            pin_memory=True)
  test_loader = DataLoader(test_ds,
                           batch_size=128,
                           shuffle=False,
                           num_workers=4,
                           pin_memory=True)

Model Mimarisi (ConvVAE)
Encoder

Conv2d(1, 32, kernel_size=4, stride=2, padding=1) â†’ 28Ã—28 â†’ 14Ã—14

Conv2d(32, 64, kernel_size=4, stride=2, padding=1) â†’ 14Ã—14 â†’ 7Ã—7

Conv2d(64, 128, kernel_size=4, stride=2, padding=1) â†’ 7Ã—7 â†’ 3Ã—3

Flatten edilmiÅŸ Ã§Ä±ktÄ± (128 Ã— 3 Ã— 3 = 1152 boyut) iki ayrÄ± tam baÄŸlÄ± katmana (FC) beslenir:

Î¼(x): Linear(128*3*3, latent_dim)

logÏƒÂ²(x): Linear(128*3*3, latent_dim)

Reparameterization Trick

ğ‘§
=
ğœ‡
(
ğ‘¥
)
+
exp
â¡
(
1
2
log
â¡
ğœ
2
(
ğ‘¥
)
)
âŠ™
ğœ–
,
ğœ–
âˆ¼
ğ‘
(
0
,
ğ¼
)
z=Î¼(x)+exp( 
2
1
â€‹
 logÏƒ 
2
 (x))âŠ™Ïµ,Ïµâˆ¼N(0,I)
Decoder

Linear(latent_dim, 128*3*3) â†’ yeniden ÅŸekillendirme: 128 Ã— 3 Ã— 3

ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, output_padding=1) â†’ 3Ã—3 â†’ 7Ã—7

ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1) â†’ 7Ã—7 â†’ 14Ã—14

ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1) â†’ 14Ã—14 â†’ 28Ã—28

Son katmanda Sigmoid aktivasyonu kullanÄ±larak Ã§Ä±ktÄ± [0, 1] aralÄ±ÄŸÄ±nda elde edilir.
