# Convolutional Variational Autoencoder (ConvVAE) on Fashion-MNIST

## Introduction  
Variational Autoencoder (VAE) modelleri, hem sÄ±kÄ±ÅŸtÄ±rma (compression) hem de yeni veri Ã¼retme (generation) yeteneÄŸine sahip generatif modellerdir.  
Bu projede, 28Ã—28 gri-ton Fashion-MNIST veri seti Ã¼zerinde bir **Convolutional VAE (ConvVAE)** eÄŸitildi. AmaÃ§lar:  
1. GÃ¶rÃ¼ntÃ¼lerin yÃ¼ksek boyutlu piksellerini, dÃ¼ÅŸÃ¼k boyutlu latent uzayda temsil edebilmek  
2. Bu temsillerden rekonstrÃ¼ksiyon ve yeni Ã¶rnekler Ã¼retebilmek  
3. Encoderâ€™Ä±n Ã§Ä±kardÄ±ÄŸÄ± latent kodlarÄ± kullanarak downstream bir sÄ±nÄ±flandÄ±rma gÃ¶revi yapmak

## Methods

### Veri HazÄ±rlama  
- **Veri KÃ¼mesi**: Fashion-MNIST (60 000 eÄŸitim, 10 000 test Ã¶rneÄŸi).  
- **Ã–znitelik Boyutu**: Her Ã¶rnek 28Ã—28 piksel, gri-ton.  
- **Normalize Etme**: Piksel deÄŸerleri [0, 1] aralÄ±ÄŸÄ±na Ã§ekildi (PyTorch `ToTensor()` ile).  
- **Batchleme**: EÄŸitim iÃ§in `batch_size = 128`, test iÃ§in `batch_size = 128`.  
- **DataLoader KullanÄ±mÄ±**:  
  ```python
  from torch.utils.data import DataLoader
  from torchvision import datasets, transforms

  transform = transforms.Compose([
      transforms.ToTensor()
  ])
  train_ds = datasets.FashionMNIST("data/fashion-mnist",
                                   train=True,
                                   download=True,
                                   transform=transform)
  test_ds = datasets.FashionMNIST("data/fashion-mnist",
                                  train=False,
                                  download=True,
                                  transform=transform)
  train_loader = DataLoader(train_ds,
                            batch_size=128,
                            shuffle=True,
                            num_workers=4,
                            pin_memory=True)
  test_loader = DataLoader(test_ds,
                           batch_size=128,
                           shuffle=False,
                           num_workers=4,
                           pin_memory=True)

### Model Mimarisi (ConvVAE)

#### Encoder
1. **Katman 1**: `Conv2d(1, 32, kernel_size=4, stride=2, padding=1)`  
   - Girdi: 28Ã—28Ã—1  
   - Ã‡Ä±ktÄ±: 14Ã—14Ã—32  
2. **Katman 2**: `Conv2d(32, 64, kernel_size=4, stride=2, padding=1)`  
   - Girdi: 14Ã—14Ã—32  
   - Ã‡Ä±ktÄ±: 7Ã—7Ã—64  
3. **Katman 3**: `Conv2d(64, 128, kernel_size=4, stride=2, padding=1)`  
   - Girdi: 7Ã—7Ã—64  
   - Ã‡Ä±ktÄ±: 3Ã—3Ã—128  
4. **Flatten ve FC KatmanlarÄ±**  
   - Ã‡Ä±ktÄ± boyutu: 128 Ã— 3 Ã— 3 = 1152  
   - **Î¼(x)**: `Linear(1152, latent_dim)`  
   - **logÏƒÂ²(x)**: `Linear(1152, latent_dim)`

#### Reparameterization Trick
\[
z = \mu(x) + \exp\Bigl(\tfrac{1}{2}\log\sigma^2(x)\Bigr)\,\odot\,\epsilon,\quad
\epsilon \sim \mathcal{N}(0, I)
\]

#### Decoder
1. **FC ve Yeniden Åekillendirme**  
   - `Linear(latent_dim, 128*3*3)`  
   - Yeniden ÅŸekillendirme: 128Ã—3Ã—3  
2. **Katman 1**:  
   `ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, output_padding=1)`  
   - Girdi: 3Ã—3Ã—128  
   - Ã‡Ä±ktÄ±: 7Ã—7Ã—64  
3. **Katman 2**:  
   `ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)`  
   - Girdi: 7Ã—7Ã—64  
   - Ã‡Ä±ktÄ±: 14Ã—14Ã—32  
4. **Katman 3**:  
   `ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)`  
   - Girdi: 14Ã—14Ã—32  
   - Ã‡Ä±ktÄ±: 28Ã—28Ã—1  
   - Aktivasyon: `Sigmoid` (Ã§Ä±ktÄ±yÄ± [0,1] aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r)

#### Tam Kod (PyTorch)
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class ConvVAE(nn.Module):
    def __init__(self, latent_dim=32):
        super().__init__()
        # Encoder
        self.enc1 = nn.Conv2d(1, 32, 4, 2, 1)    # 28â†’14
        self.enc2 = nn.Conv2d(32, 64, 4, 2, 1)   # 14â†’7
        self.enc3 = nn.Conv2d(64, 128, 4, 2, 1)  # 7â†’3
        self.fc_mu  = nn.Linear(128*3*3, latent_dim)
        self.fc_log = nn.Linear(128*3*3, latent_dim)

        # Decoder
        self.fc_dec = nn.Linear(latent_dim, 128*3*3)
        self.dec1   = nn.ConvTranspose2d(128, 64, 4, 2, 1, output_padding=1)  # 3â†’7
        self.dec2   = nn.ConvTranspose2d(64, 32, 4, 2, 1)                       # 7â†’14
        self.dec3   = nn.ConvTranspose2d(32, 1, 4, 2, 1)                        # 14â†’28

    def encode(self, x):
        h = F.relu(self.enc1(x))
        h = F.relu(self.enc2(h))
        h = F.relu(self.enc3(h))
        h = h.view(h.size(0), -1)  # [batch, 128*3*3]
        return self.fc_mu(h), self.fc_log(h)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        h = F.relu(self.fc_dec(z))
        h = h.view(-1, 128, 3, 3)
        h = F.relu(self.dec1(h))
        h = F.relu(self.dec2(h))
        return torch.sigmoid(self.dec3(h))

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

## KayÄ±p Fonksiyonu

### Reconstruction Loss (Binary Cross-Entropy)
\[
\mathrm{BCE} = -\sum_{i=1}^{N} \bigl[x_i \,\log \hat{x}_i + (1 - x_i)\,\log\bigl(1 - \hat{x}_i\bigr)\bigr], \quad (\text{reduction='sum'})
\]

```python
import torch.nn.functional as F

# recon_x: model.decode(z) Ã§Ä±ktÄ±sÄ± (28Ã—28 boyutunda, sigmoid ile [0,1] aralÄ±ÄŸÄ±nda)
# x: orijinal giriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼
BCE = F.binary_cross_entropy(recon_x, x, reduction="sum")

### Kullbackâ€“Leibler Divergence (KLD)

\[
\mathrm{KLD} = -\frac{1}{2} \sum_{j=1}^{d} \bigl(1 + \log(\sigma_j^2)\;-\;\mu_j^2\;-\;\sigma_j^2 \bigr)
\]
Burada:
- \(d = \text{latent\_dim}\)  
- \(\mu_j\) ve \(\sigma_j^2 = \exp(\log\sigma_j^2)\) sÄ±rasÄ±yla encoderâ€™dan Ã§Ä±kan ortalama ve log varyans parametreleridir.

```python
# mu: [batch, latent_dim] boyutunda ortalama vektÃ¶rÃ¼
# logvar: [batch, latent_dim] boyutunda log varyans vektÃ¶rÃ¼
KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

### Toplam Loss

\[
\mathcal{L}(x) = \underbrace{\mathrm{BCE}(x, \hat{x})}_{\text{Reconstruction}} 
\;+\; 
\underbrace{\mathrm{KLD}\bigl(q(z \mid x)\,\|\,\mathcal{N}(0, I)\bigr)}_{\text{Regularization}}
\]

```python
import torch.nn.functional as F

def loss_function(recon_x, x, mu, logvar):
    # Reconstruction (Binary Cross-Entropy)
    BCE = F.binary_cross_entropy(recon_x, x, reduction="sum")
    # Kullbackâ€“Leibler Divergence
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD

### EÄŸitim ProsedÃ¼rÃ¼

#### Parametreler
- `batch_size = 128`
- `epochs = 100`
- `learning_rate = 5e-4`
- Optimizer: `Adam(model.parameters(), lr=5e-4)`

#### EÄŸitim DÃ¶ngÃ¼sÃ¼
```python
from torch.optim import Adam

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ConvVAE(latent_dim=32).to(device)
optimizer = Adam(model.parameters(), lr=5e-4)

for epoch in range(1, epochs + 1):
    model.train()
    train_loss = 0
    for data, _ in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        recon, mu, logvar = model(data)
        loss = loss_function(recon, data, mu, logvar)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    avg_train_loss = train_loss / len(train_loader.dataset)

    model.eval()
    test_loss = 0
    with torch.no_grad():
        for data, _ in test_loader:
            data = data.to(device)
            recon, mu, logvar = model(data)
            test_loss += loss_function(recon, data, mu, logvar).item()
    avg_test_loss = test_loss / len(test_loader.dataset)

    print(f"Epoch {epoch}: Train loss {avg_train_loss:.2f}, Test loss {avg_test_loss:.2f}")
Downstream GÃ¶rev: Latent Ã–zelliklerle SÄ±nÄ±flandÄ±rma
EÄŸitilmiÅŸ ConvVAE modelinin encoderâ€™Ä±ndan Ã§Ä±karÄ±lan 
ğœ‡
(
ğ‘¥
)
âˆˆ
ğ‘…
32
Î¼(x)âˆˆR 
32
  boyutlu latent vektÃ¶rler,
Ã¶zellik (feature) olarak RandomForestClassifier iÃ§ine beslenir.

AdÄ±mlar:

EÄŸitilmiÅŸ modeli yÃ¼kleme:
```python
model = ConvVAE(latent_dim=32).to(device)
model.load_state_dict(torch.load("src/checkpoints/convvae_fashionmnist.pth", map_location=device))
model.eval()
'''
Latent Ã‡Ä±karÄ±mÄ±:
```python
import numpy as np
from torch.utils.data import DataLoader

def extract_latent(loader):
    feats, labels = [], []
    with torch.no_grad():
        for data, target in loader:
            data = data.to(device)
            mu, _ = model.encode(data)
            feats.append(mu.cpu().numpy())
            labels.append(target.numpy())
    return np.concatenate(feats), np.concatenate(labels)

X_train, y_train = extract_latent(train_loader)
X_test,  y_test  = extract_latent(test_loader)
'''
Random Forest EÄŸitimi ve DeÄŸerlendirme:
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)
preds = clf.predict(X_test)
acc = accuracy_score(y_test, preds)
print(f"Classification accuracy: {acc*100:.2f}%")
cm = confusion_matrix(y_test, preds)
'''
Performans:

Latent boyut = 16 ile denemede %84.01 doÄŸruluk elde edildi.

Latent boyut = 32â€™de benzer veya daha yÃ¼ksek doÄŸruluk beklenir.

Results
Loss Curves

Mavi: EÄŸitim kaybÄ±, Turuncu: Test kaybÄ±

epochâ€™ta â‰ˆ 308; sonraki epochâ€™larda âˆ¼ 236 civarÄ±na indi

100 epoch sonunda plateau, eÄŸitim ve test kayÄ±plarÄ± birbirine yakÄ±n (overfitting az)

RekonstrÃ¼ksiyon Ã–rnekleri

Ãœst satÄ±r: Test setten alÄ±nan orijinal resimler

Alt satÄ±r: ConvVAEâ€™nin Ã¼rettiÄŸi rekonstrÃ¼ksiyonlar

Kenar detaylarÄ± belirginleÅŸmiÅŸ; bulanÄ±klÄ±k bÃ¼yÃ¼k Ã¶lÃ§Ã¼de azalmÄ±ÅŸ

Ã–rnek Ãœretim (Samples)

Latent uzaydan rastgele 
ğ‘§
âˆ¼
ğ‘
(
0
,
ğ¼
)
zâˆ¼N(0,I) Ã§ekilip decoderâ€™dan geÃ§irilerek Ã¼retildi

â€œSneakerâ€, â€œPulloverâ€ vb. sÄ±nÄ±f hatlarÄ± seÃ§ilebiliyor, ancak ince detaylar hÃ¢lÃ¢ biraz net deÄŸil

Latent Embedding SÄ±nÄ±flandÄ±rma

DoÄŸruluk: %84.01 (latent_dim=16)

SÄ±nÄ±flandÄ±rÄ±cÄ±: Random Forest (n_estimators=100)

KarmaÅŸÄ±klÄ±k Matrisi
AÅŸaÄŸÄ±daki tablo, test set Ã¼zerindeki sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rmalÄ± karmaÅŸÄ±klÄ±k matrisini gÃ¶stermektedir (satÄ±rlar gerÃ§ek sÄ±nÄ±flar, sÃ¼tunlar tahmin edilen sÄ±nÄ±flar):
| True\Pred | Pred_0 | Pred_1 | Pred_2 | Pred_3 | Pred_4 | Pred_5 | Pred_6 | Pred_7 | Pred_8 | Pred_9 | Total |
|-----------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|-------|
| **True_0**    | 841    | 1      | 1      | 2      | 2      | 4      | 1      | 2      | 1      | 3      | 858   |
| **True_1**    | 1      | 927    | 0      | 5      | 0      | 1      | 3      | 2      | 5      | 2      | 946   |
| **True_2**    | 5      | 1      | 794    | 7      | 6      | 4      | 8      | 8      | 19     | 3      | 855   |
| **True_3**    | 5      | 10     | 9      | 843    | 6      | 16     | 5      | 4      | 18     | 6      | 922   |
| **True_4**    | 2      | 3      | 1      | 3      | 838    | 4      | 4      | 5      | 18     | 4      | 882   |
| **True_5**    | 8      | 1      | 1      | 16     | 2      | 684    | 11     | 33     | 10     | 22     | 788   |
| **True_6**    | 7      | 3      | 7      | 1      | 7      | 4      | 850    | 1      | 5      | 2      | 893   |
| **True_7**    | 0      | 3      | 4      | 2      | 4      | 19     | 0      | 893    | 2      | 2      | 929   |
| **True_8**    | 1      | 13     | 6      | 11     | 17     | 11     | 5      | 5      | 812    | 20     | 901   |
| **True_9**    | 4      | 5      | 0      | 3      | 0      | 19     | 1      | 3      | 9      | 913    | 957   |
| **Total** | 874    | 967    | 813    | 892    | 882    | 750    | 888    | 961    | 880    | 997    | 9123  |

Discussion
BaÅŸarÄ±lar

Convolutional mimari, tam baÄŸlantÄ±lÄ± VAEâ€™ye kÄ±yasla Ã§ok daha net rekonstrÃ¼ksiyonlar sundu.

Latent kodlar (%84 doÄŸruluk) downstream gÃ¶revlerde anlamlÄ± temsil oluÅŸturdu.

KÄ±sÄ±tlar ve Ä°yileÅŸtirme AlanlarÄ±

Daha Derin Mimari

Ek Conv katmanlarÄ± (Ã¶r. 256 filtre), BatchNorm/LeakyReLU eklenebilir.

EÄŸitim Teknikleri

Î²-VAE (â€œÎ²>1â€) ile KLDâ€™ye aÄŸÄ±rlÄ±k vererek latent uzayÄ±n dÃ¼zenini iyileÅŸtirme.

Ã–ÄŸrenme OranÄ± PlanlayÄ±cÄ±larÄ±: ReduceLROnPlateau veya CosineAnnealing eklenebilir.

Epoch sayÄ±sÄ±nÄ± 150â€“200â€™e Ã§Ä±karmak uzun vadeli iyileÅŸmeler sunabilir.

GÃ¶rsel KayÄ±p Terimleri

Perceptual Loss (VGG tabanlÄ±) veya Feature Matching ekleyerek daha net Ã§Ä±ktÄ± saÄŸlama.

Latent Boyut

32â†’64/128 deneyerek latent uzayÄ±n kapasitesini artÄ±rma; 2D gÃ¶rselleÅŸtirme iÃ§in ayrÄ± bir modelle t-SNE/PCA analizi yapÄ±labilir.

References
D. P. Kingma & M. Welling, â€œAuto-Encoding Variational Bayes,â€ ICLR 2014.

Fashion-MNIST dataset, https://github.com/zalandoresearch/fashion-mnist

PyTorch dokÃ¼mantasyonu: https://pytorch.org/docs/stable/


