{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1cfb3d",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE) on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a50537",
   "metadata": {},
   "source": [
    "Bu notebook, VAE projesinin hızlı prototipini ve görselleştirmelerini içerir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ba516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.FashionMNIST(\"data/fashion-mnist\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3fdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images, labels = next(iter(train_loader))\n",
    "fig, axes = plt.subplots(3,3,figsize=(6,6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    img = images[i].squeeze()\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8893d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import VAE\n",
    "from utils import visualize_reconstruction, sample_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE(latent_dim=16).to(device)\n",
    "# Eğer daha önce eğitim yaptıysan, checkpoint yükle\n",
    "torch_load_path = \"../checkpoints/vae_fashionmnist.pth\"\n",
    "if os.path.exists(torch_load_path):\n",
    "    model.load_state_dict(torch.load(torch_load_path, map_location=device))\n",
    "    print(\"Model checkpoint yüklendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8723cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstrüksiyonları görselleştir\n",
    "visualize_reconstruction(model, train_loader, device, num_images=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3108ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni örnekler üret\n",
    "sample_images(model, device, num_samples=16, latent_dim=16)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
